{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "embedding_size = 150\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('../data/shakespeare.txt').read())\n",
    "file_len = len(file)\n",
    "\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne, my sovereign, with all speed.\n",
      "\n",
      "KING HENRY VI:\n",
      "My Lord of Somerset, what youth is that,\n",
      "Of whom you seem to have so tender care?\n",
      "\n",
      "SOMERSET:\n",
      "My liege, it is young Henry, earl of Richmond.\n",
      "\n",
      "KING HENRY\n",
      "\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())\n",
    "print('')\n",
    "print(len(random_chunk()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17, 14, 21, 21, 24])\n",
      "tensor([11, 14, 14, 23, 94, 28, 29, 30, 13, 34, 18, 23, 16, 94, 17, 24, 32, 94,\n",
      "        44, 94, 22, 10, 34, 94, 12, 24, 22, 25, 10, 27, 14, 96, 55, 17, 18, 28,\n",
      "        94, 25, 27, 18, 28, 24, 23, 94, 32, 17, 14, 27, 14, 94, 44, 94, 21, 18,\n",
      "        31, 14, 94, 30, 23, 29, 24, 94, 29, 17, 14, 94, 32, 24, 27, 21, 13, 77,\n",
      "        96, 36, 23, 13, 94, 15, 24, 27, 94, 11, 14, 12, 10, 30, 28, 14, 94, 29,\n",
      "        17, 14, 94, 32, 24, 27, 21, 13, 94, 18, 28, 94, 25, 24, 25, 30, 21, 24,\n",
      "        30, 28, 96, 36, 23, 13, 94, 17, 14, 27, 14, 94, 18, 28, 94, 23, 24, 29,\n",
      "        94, 10, 94, 12, 27, 14, 10, 29, 30, 27, 14, 94, 11, 30, 29, 94, 22, 34,\n",
      "        28, 14, 21, 15, 73, 96, 44, 94, 12, 10, 23, 23, 24, 29, 94, 13, 24, 94,\n",
      "        18, 29, 78, 94, 34, 14, 29, 94, 44, 68, 21, 21, 94, 17, 10, 22, 22, 14,\n",
      "        27, 94, 18, 29, 94, 24, 30, 29, 75, 96, 48, 34, 94, 11, 27, 10, 18, 23,\n",
      "        94, 44, 68])\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('hello'))\n",
    "print(char_tensor(random_chunk()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 29, 94, 18, 28, 68, 29, 96, 34, 24, 30, 27, 94, 32, 24, 27, 28, 17,\n",
      "        18, 25, 68, 28, 94, 25, 21, 14, 10, 28, 30, 27, 14, 94, 44, 94, 28, 17,\n",
      "        10, 21, 21, 94, 13, 24, 94, 32, 18, 29, 17, 94, 29, 17, 18, 28, 94, 32,\n",
      "        18, 12, 20, 14, 13, 94, 12, 10, 18, 29, 18, 15, 15, 82, 96, 96, 40, 54,\n",
      "        38, 36, 47, 56, 54, 77, 96, 55, 27, 30, 21, 34, 73, 94, 24, 15, 15, 18,\n",
      "        12, 14, 27, 73, 94, 11, 14, 12, 10, 30, 28, 14, 94, 17, 14, 94, 17, 10,\n",
      "        29, 17, 94, 28, 24, 22, 14, 94, 24, 15, 15, 14, 23, 12, 14, 28, 94, 18,\n",
      "        23, 94, 17, 18, 22, 96, 29, 17, 10, 29, 94, 29, 17, 24, 30, 94, 32, 24,\n",
      "        30, 21, 13, 28, 29, 94, 13, 18, 28, 12, 24, 31, 14, 27, 94, 18, 15, 94,\n",
      "        29, 17, 24, 30, 94, 12, 24, 30, 21, 13, 28, 29, 73, 94, 21, 14, 29, 94,\n",
      "        17, 18, 22, 96, 12, 24, 23, 29, 18, 23, 30, 14, 94, 18, 23, 94, 17, 18,\n",
      "        28, 94])\n",
      "tensor([29, 94, 18, 28, 68, 29, 96, 34, 24, 30, 27, 94, 32, 24, 27, 28, 17, 18,\n",
      "        25, 68, 28, 94, 25, 21, 14, 10, 28, 30, 27, 14, 94, 44, 94, 28, 17, 10,\n",
      "        21, 21, 94, 13, 24, 94, 32, 18, 29, 17, 94, 29, 17, 18, 28, 94, 32, 18,\n",
      "        12, 20, 14, 13, 94, 12, 10, 18, 29, 18, 15, 15, 82, 96, 96, 40, 54, 38,\n",
      "        36, 47, 56, 54, 77, 96, 55, 27, 30, 21, 34, 73, 94, 24, 15, 15, 18, 12,\n",
      "        14, 27, 73, 94, 11, 14, 12, 10, 30, 28, 14, 94, 17, 14, 94, 17, 10, 29,\n",
      "        17, 94, 28, 24, 22, 14, 94, 24, 15, 15, 14, 23, 12, 14, 28, 94, 18, 23,\n",
      "        94, 17, 18, 22, 96, 29, 17, 10, 29, 94, 29, 17, 24, 30, 94, 32, 24, 30,\n",
      "        21, 13, 28, 29, 94, 13, 18, 28, 12, 24, 31, 14, 27, 94, 18, 15, 94, 29,\n",
      "        17, 24, 30, 94, 12, 24, 30, 21, 13, 28, 29, 73, 94, 21, 14, 29, 94, 17,\n",
      "        18, 22, 96, 12, 24, 23, 29, 18, 23, 30, 14, 94, 18, 23, 94, 17, 18, 28,\n",
      "        94, 12])\n"
     ]
    }
   ],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target\n",
    "\n",
    "inp, target = random_training_set()\n",
    "print(inp)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size,hidden_size,num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        \n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out, hidden = model(inp, hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        #_,top_i = torch.max(output_dist,dim=0)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor(3.4037, grad_fn=<DivBackward0>) \n",
      "\n",
      "e ce s  -n et t walet i s \n",
      " ce  nep s ~hc ,\n",
      " Yic.issewlri. cap}e iaR\u000b",
      "\n",
      "w hH h tmRou ds hRO sf>e ugnWees\n",
      "hihnEyvoMh.wn  \u000b",
      "Afou as ni * ddi ood osmhoHe :d.Et eaoec}th,fioe0ejsiR ;tool:hK \n",
      "\n",
      "\n",
      "\n",
      " tensor(2.4203, grad_fn=<DivBackward0>) \n",
      "\n",
      "bewsre as thiss ben;Tu thed ar on yt ant haor winniile giat or igh the.\n",
      "\n",
      "Non thee son at lore to and in Bou anksan:\n",
      "Borly anm ther of and:\n",
      "Yhe or mat beas meme thee eecend pent in nenou dame I baat is \n",
      "\n",
      "\n",
      "\n",
      " tensor(2.2073, grad_fn=<DivBackward0>) \n",
      "\n",
      "bleall githnt fist ghare blost the, loth ginst'r hour the we heell bohs Irenou afe nia keld I mof fnere'lE no int-anes the the ther, ay prinstfand mearis sows wo a sinow and he no'ld the therno wh:\n",
      "Tha\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.4625, grad_fn=<DivBackward0>) \n",
      "\n",
      "bcis thing, thech,\n",
      "Mave prenting wordourturfan, and you\n",
      "me my of bly way,\n",
      "Dest\n",
      "And raiss meome preare that in'd gribs me swartall shood not wither,\n",
      "BY JPAIN):\n",
      "I cond theed younce, wo gactend, broust fo\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.1306, grad_fn=<DivBackward0>) \n",
      "\n",
      "bing thinterde, manst,\n",
      "That dords counse a and well and Bay the he thell and no What hem of the a my thou conantense hith mate a that so pothed yigh then firtoss plbat, the to sor arth colle tith my fo\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9035, grad_fn=<DivBackward0>) \n",
      "\n",
      "bricen warse of Lor; Oo blaust had him deat ootht he fnow mill och dichisself Canesion,\n",
      "That sordisc,\n",
      "He maid swime, that it that it this that rool so has buts saom mand.\n",
      "\n",
      "O7 I tsat, havi'f and hat ber\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0056, grad_fn=<DivBackward0>) \n",
      "\n",
      "be mowh all:\n",
      "Hemple of would of lide,\n",
      "But thy wrich and marce.\n",
      "\n",
      "PEMRET:\n",
      "I laEt till but my peato sthou houl to mane of man do cove my prame have\n",
      "dought gall it.\n",
      "\n",
      "QUUEEN IUTAK:\n",
      "How siin aget, though and\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-9c5be58028ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-d68369e8d818>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y_ = torch.LongTensor([y_.item()]).to(device)\n",
    "        y, hidden = model(x,hidden)\n",
    "        loss += criterion(y, y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
