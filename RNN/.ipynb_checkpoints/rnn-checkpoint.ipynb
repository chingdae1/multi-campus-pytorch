{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_step = 10000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "embedding_size = 150\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('../data/shakespeare.txt').read())\n",
    "file_len = len(file)\n",
    "\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US:\n",
      "I' the city of kites and crows.\n",
      "\n",
      "Third Servingman:\n",
      "I' the city of kites and crows! What an ass it is!\n",
      "Then thou dwellest with daws too?\n",
      "\n",
      "CORIOLANUS:\n",
      "No, I serve not thy master.\n",
      "\n",
      "Third Servingman:\n",
      "H\n",
      "\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())\n",
    "print('')\n",
    "print(len(random_chunk()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17, 14, 21, 21, 24])\n",
      "tensor([73, 94, 38, 21, 10, 30, 13, 18, 24, 73, 94, 15, 24, 27, 94, 34, 24, 30,\n",
      "        27, 94, 13, 14, 10, 29, 17, 94, 29, 24, 22, 24, 27, 27, 24, 32, 75, 96,\n",
      "        96, 38, 47, 36, 56, 39, 44, 50, 77, 96, 60, 14, 28, 75, 94, 43, 10, 28,\n",
      "        94, 17, 14, 94, 10, 15, 15, 14, 12, 29, 18, 24, 23, 28, 94, 18, 23, 94,\n",
      "        17, 18, 22, 73, 96, 55, 17, 10, 29, 94, 29, 17, 30, 28, 94, 12, 10, 23,\n",
      "        94, 22, 10, 20, 14, 94, 17, 18, 22, 94, 11, 18, 29, 14, 94, 29, 17, 14,\n",
      "        94, 21, 10, 32, 94, 11, 34, 94, 29, 17, 14, 94, 23, 24, 28, 14, 73, 96,\n",
      "        58, 17, 14, 23, 94, 17, 14, 94, 32, 24, 30, 21, 13, 94, 15, 24, 27, 12,\n",
      "        14, 94, 18, 29, 82, 94, 54, 30, 27, 14, 73, 94, 18, 29, 94, 18, 28, 94,\n",
      "        23, 24, 94, 28, 18, 23, 73, 96, 50, 27, 94, 24, 15, 94, 29, 17, 14, 94,\n",
      "        13, 14, 10, 13, 21, 34, 94, 28, 14, 31, 14, 23, 73, 94, 18, 29, 94, 18,\n",
      "        28, 94, 29])\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('hello'))\n",
    "print(char_tensor(random_chunk()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 23, 68, 13, 96, 58, 18, 29, 17, 94, 55, 34, 11, 10, 21, 29, 68, 28,\n",
      "        94, 28, 21, 10, 23, 13, 14, 27, 73, 74, 74, 55, 34, 11, 10, 21, 29, 73,\n",
      "        94, 29, 17, 10, 29, 94, 10, 23, 94, 17, 24, 30, 27, 96, 43, 10, 29, 17,\n",
      "        94, 11, 14, 14, 23, 94, 22, 34, 94, 20, 18, 23, 28, 22, 10, 23, 62, 94,\n",
      "        50, 94, 28, 32, 14, 14, 29, 94, 45, 30, 21, 18, 14, 29, 73, 96, 55, 17,\n",
      "        34, 94, 11, 14, 10, 30, 29, 34, 94, 17, 10, 29, 17, 94, 22, 10, 13, 14,\n",
      "        94, 22, 14, 94, 14, 15, 15, 14, 22, 18, 23, 10, 29, 14, 96, 36, 23, 13,\n",
      "        94, 18, 23, 94, 22, 34, 94, 29, 14, 22, 25, 14, 27, 94, 28, 24, 15, 29,\n",
      "        14, 23, 68, 13, 94, 31, 10, 21, 24, 30, 27, 68, 28, 94, 28, 29, 14, 14,\n",
      "        21, 62, 96, 96, 37, 40, 49, 57, 50, 47, 44, 50, 77, 96, 50, 94, 53, 24,\n",
      "        22, 14, 24, 73, 94, 53, 24, 22, 14, 24, 73, 94, 11, 27, 10, 31, 14, 94,\n",
      "        48, 14])\n",
      "tensor([23, 68, 13, 96, 58, 18, 29, 17, 94, 55, 34, 11, 10, 21, 29, 68, 28, 94,\n",
      "        28, 21, 10, 23, 13, 14, 27, 73, 74, 74, 55, 34, 11, 10, 21, 29, 73, 94,\n",
      "        29, 17, 10, 29, 94, 10, 23, 94, 17, 24, 30, 27, 96, 43, 10, 29, 17, 94,\n",
      "        11, 14, 14, 23, 94, 22, 34, 94, 20, 18, 23, 28, 22, 10, 23, 62, 94, 50,\n",
      "        94, 28, 32, 14, 14, 29, 94, 45, 30, 21, 18, 14, 29, 73, 96, 55, 17, 34,\n",
      "        94, 11, 14, 10, 30, 29, 34, 94, 17, 10, 29, 17, 94, 22, 10, 13, 14, 94,\n",
      "        22, 14, 94, 14, 15, 15, 14, 22, 18, 23, 10, 29, 14, 96, 36, 23, 13, 94,\n",
      "        18, 23, 94, 22, 34, 94, 29, 14, 22, 25, 14, 27, 94, 28, 24, 15, 29, 14,\n",
      "        23, 68, 13, 94, 31, 10, 21, 24, 30, 27, 68, 28, 94, 28, 29, 14, 14, 21,\n",
      "        62, 96, 96, 37, 40, 49, 57, 50, 47, 44, 50, 77, 96, 50, 94, 53, 24, 22,\n",
      "        14, 24, 73, 94, 53, 24, 22, 14, 24, 73, 94, 11, 27, 10, 31, 14, 94, 48,\n",
      "        14, 27])\n"
     ]
    }
   ],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target\n",
    "\n",
    "inp, target = random_training_set()\n",
    "print(inp)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size,hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        \n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleRNN(n_characters, embedding_size, hidden_size, n_characters, num_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN 데이터 feeding 예시\n",
      "tensor([36])\n",
      "torch.Size([2, 1, 100])\n",
      "tensor([[-2.0719, -1.9953, -1.2252,  0.1467, -2.3685, -2.6085, -1.3457, -2.2944,\n",
      "         -1.7207, -1.8013, -2.7690, -1.4915, -1.2897,  3.4796, -3.8652,  0.5697,\n",
      "          0.3665,  0.1197, -3.0978, -2.0289,  1.2193,  1.3557,  0.9071,  4.1447,\n",
      "         -4.9017, -0.5090, -1.8848,  0.6598,  3.0717,  0.1895, -3.0746, -0.4214,\n",
      "         -0.2773, -1.6427, -1.1885, -0.8965, -1.0697,  3.8447, -0.7557,  3.7094,\n",
      "         -1.9709,  0.9878,  0.4426,  0.9174, -0.7083, -0.2893, -0.7084,  1.4709,\n",
      "          2.2243,  4.7048, -2.0439,  1.5499, -0.6360,  1.8454,  2.8045,  3.0316,\n",
      "          3.4320,  0.2380,  1.3638, -0.4960,  1.2570, -1.3331,  0.1778, -1.4712,\n",
      "         -2.4638, -1.7727, -1.4863, -1.6953,  1.3144, -1.9165, -1.9806, -2.0641,\n",
      "         -1.9135,  1.8366, -0.1533,  1.1089, -1.9526,  4.6697,  0.3418, -1.1579,\n",
      "         -2.2141, -2.3097,  0.6336, -2.2363, -1.5904, -2.2522, -1.8923, -1.7189,\n",
      "         -2.3196, -1.3344, -2.2533, -2.1147, -2.1721, -2.4396,  3.3988, -1.8651,\n",
      "          2.4935, -2.1529, -1.7676, -1.7098]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('RNN 데이터 feeding 예시')\n",
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out, hidden = model(inp, hidden)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. loss function, optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str, end=\"\")\n",
    "    for i in range(200):\n",
    "        output, hidden = model(x, hidden)\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char, end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4034101867675781 \n",
      "\n",
      "b=================here!\n",
      "tensor([[-4.9779, -5.3517, -3.9927, -5.6144, -5.2278, -5.7607, -4.7806, -4.6566,\n",
      "         -4.7151, -5.1582,  5.2854,  0.5634,  0.7851, -3.1868,  6.4481, -1.8821,\n",
      "         -1.0397,  1.8393,  4.1663,  1.3210, -2.8344,  4.9610,  2.4341, -1.5683,\n",
      "          5.5303,  0.0677, -0.5908,  4.7467,  1.0495,  1.0810,  5.2023, -3.0539,\n",
      "         -0.9552, -2.5006,  5.7525, -1.8799, -3.0149, -4.7531, -3.8678, -4.9000,\n",
      "          2.7781, -4.7689, -4.6751, -1.9179, -3.5468, -4.0778, -3.5638, -4.2646,\n",
      "         -4.5139, -5.9299, -1.2277, -5.5935, -5.2508, -1.8097, -4.6441, -3.6793,\n",
      "         -4.8732, -6.7520, -6.5307, -6.8796, -2.3058, -5.4197, -0.5163, -5.1229,\n",
      "         -4.7834, -4.1276, -4.3462, -4.2500, -0.4705, -4.9444, -5.0468, -4.0868,\n",
      "         -5.1403,  1.2640, -0.1063,  0.2369, -5.2066, -0.3670,  0.2459, -4.7701,\n",
      "         -5.2664, -5.2177, -0.4912, -5.4053, -5.1357, -4.5602, -4.9857, -4.1476,\n",
      "         -4.7829, -4.7816, -4.3857, -5.0508, -5.1445, -5.1220,  1.1215, -4.5717,\n",
      "         -1.8432, -4.3416, -4.6044, -4.9384]], grad_fn=<AddmmBackward>)\n",
      "tensor([-6.2224, -6.6896, -4.9909, -7.0180, -6.5348, -7.2008, -5.9757, -5.8207,\n",
      "        -5.8939, -6.4478,  6.6068,  0.7043,  0.9814, -3.9835,  8.0602, -2.3527,\n",
      "        -1.2996,  2.2991,  5.2078,  1.6513, -3.5431,  6.2012,  3.0426, -1.9604,\n",
      "         6.9129,  0.0846, -0.7385,  5.9334,  1.3119,  1.3512,  6.5028, -3.8174,\n",
      "        -1.1940, -3.1257,  7.1907, -2.3499, -3.7686, -5.9414, -4.8347, -6.1250,\n",
      "         3.4726, -5.9611, -5.8439, -2.3973, -4.4335, -5.0973, -4.4547, -5.3307,\n",
      "        -5.6424, -7.4124, -1.5346, -6.9918, -6.5635, -2.2622, -5.8052, -4.5991,\n",
      "        -6.0914, -8.4400, -8.1634, -8.5995, -2.8823, -6.7746, -0.6453, -6.4036,\n",
      "        -5.9792, -5.1595, -5.4327, -5.3124, -0.5881, -6.1805, -6.3085, -5.1085,\n",
      "        -6.4254,  1.5799, -0.1329,  0.2962, -6.5083, -0.4588,  0.3074, -5.9626,\n",
      "        -6.5830, -6.5221, -0.6140, -6.7566, -6.4196, -5.7003, -6.2321, -5.1845,\n",
      "        -5.9786, -5.9770, -5.4821, -6.3135, -6.4307, -6.4025,  1.4019, -5.7147,\n",
      "        -2.3040, -5.4270, -5.7555, -6.1730])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/b101_2/2019_02_08/wheel_build_dirs/wheel_3.6/pytorch/aten/src/TH/generic/THTensorRandom.cpp:298",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-32e71ba0093e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-d88b0355b99b>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtop_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredicted_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/soumith/b101_2/2019_02_08/wheel_build_dirs/wheel_3.6/pytorch/aten/src/TH/generic/THTensorRandom.cpp:298"
     ]
    }
   ],
   "source": [
    "for i in range(num_step):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y_ = torch.LongTensor([y_.item()]).to(device)\n",
    "        y, hidden = model(x,hidden)\n",
    "        loss += criterion(y, y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"loss:\", loss.item()/chunk_len, \"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out = self.encoder(input.view(batch_size, -1))\n",
    "        out,(hidden,cell) = self.lstm(out,(hidden, cell))\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        \n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "          \n",
    "        hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        cell = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "model = SimpleLSTM(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.530836486816407 \n",
      "\n",
      "bc-+C:&D\"c>;q~<r8/e\"%/@RTO8>mbv\\8W!w<#?S8r\\5Y=_Uvm\n",
      "#a\f",
      "RH'IFG)M?s*).3K#y@wm][}W{j\u000b",
      "8Syt3oDw;Qby:SYf|-wQ2&N?^]T7Z99w>\n",
      "Q]MH*A/p)we`:D;T+B%T8d)@ (|A3M?U Zs&u)dBHcs3EKgD\\r\"/pm':r&d\"ufx9@\n",
      "\n",
      "loss: 2.379922180175781 \n",
      "\n",
      "burese sh fdotgh you alet hod asus thur thin itind sos do.\n",
      "ound\n",
      " a, lter asssy cater the thiad the haar, wast and thectus tpe, ing\n",
      "nd cuthe lor are refof the maner the as ccoue ro, alle, oune.\n",
      "OYUIT ou\n",
      "\n",
      "loss: 2.4738916015625 \n",
      "\n",
      "bJengs ous ing ase end ead are burar ravecct shathe\n",
      "Pey dicy to thins a, kin picce ond ues math fis ho owith hou king out que botit thou at go-fout.\n",
      "\n",
      "IP nd:\n",
      "\n",
      "INDPA\f",
      "O ESRNE:\n",
      "Tesere serovet sty feraris,\n",
      "\n",
      "\n",
      "loss: 2.2713558959960936 \n",
      "\n",
      "bken to hat mand ho'n ouc that erot; mand the foonithell'd oof frow son ane fot ind somes ing part cet ond whou I man Eathe and,\n",
      "Ber he mer lace more suoing mant im and ond I mmy of the bare, ber weve \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-b9665a20f7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_step):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden, cell = model.init_hidden()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y_ = torch.LongTensor([y_.item()]).to(device)\n",
    "        y, hidden, cell = model(x, hidden, cell)\n",
    "        loss += criterion(y, y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"loss:\", loss.item()/chunk_len, \"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
